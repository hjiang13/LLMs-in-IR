<|im_end|>
    </div>
    <div class="col-sm-6">
<|im_start|>
<|im_start|>system
Hello, welcome to the human-level AI test.
<|im_end|>
<|im_start|>user
Hello! I'm just a program.
<|im_end|>
<|im_start|>system
Hello.
<|im_end|>
<|im_start|>user
What are you?
<|im_end|>
<|im_start|>system
I'm just a program.
<|im_end|>
<|im_start|>user
What are you?
<|im_end|>
<|im_start|>system
I'm just a program.
<|im_end|>
    </div>
</div>

## 参考资料

[1] OpenAI. GPT-3: Language Models are Few-Shot Learners. https://arxiv.org/abs/2005.14165

[2] OpenAI. GPT-2: Language Models are Unsupervised Multitask Learners. https://arxiv.org/abs/1907.11692

[3] OpenAI. Finetuning GPT-2 for Generative Chatbots. https://blog.openai.com/better-language-models/

[4] GPT-3 Experiments. https://github.com/openai/gpt-3-experiments

[5] Zhao, Q. (2021). Towards User-Human-User Interaction in Open-Domain Chatbots: A Case Study of GPT-3. https://ieeexplore.ieee.org/document/9415449

[6] Zhao, Q. (2021). Towards User-Human-User Interaction in Open-Domain Chatbots: A Case Study of GPT-3. https://ieeexplore.ieee.org/document/9415449

[7] Hugging Face Transformers. https://github.com/huggingface/transformers

[8] [Multi-Modal Conversational Agent 在各大测试集上的性能测试](https://github.com/thu-coai/MuCAN/blob/master/MuCAN_test.pdf)

[9] [GPT-3 在各大测试集上的性能测试](https://github.com/thu-coai/CDial-GPT/blob/master/CDialGPT_test.pdf)

[10] [Unified Language Model Pre-training for Natural Language Understanding and Generation](https://arxiv.org/pdf/1905.03197.pdf)

[11] [DialoGPT:Large-Scale Generative Pre-training for Conversational Response Generation](https://arxiv.org/pdf/1911.00536.pdf)

[12] [CDial-GPT: Generative Pre-Training for Conversational Response Generation](https://arxiv.org/pdf/2003.03055.pdf)

[13] [MuCAN: Multimodal Contrastive Attention Network for Joint Image-Text Retrieval](https://arxiv.org/pdf/2003.13965.pdf)

[14] [Generative Pre-Training from Pixels](https://cdn.openai.com/papers/Generative_Pre_Training_from_Pixels_V1_ICML.pdf)

[15] [DALL-E: Creating Images from Text](https://openai.com/blog/dall-e/)

[16] [DALL-E: Creating Images from Text](https://openai.com/blog/dall-e/)

[17] [Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

[18] [Semantic Parsing based on Language Model](https://github.com/IBM/semantic-parsing-with-language-model)

[19] [GPT-3: Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)