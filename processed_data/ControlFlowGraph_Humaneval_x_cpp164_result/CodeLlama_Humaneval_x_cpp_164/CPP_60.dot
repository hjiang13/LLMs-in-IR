<|im_start|>system
        Here is the control flow graph:

        ```
        digraph G {
            label="bb2";
            labelloc=t;
            labeljust=c;
            style=filled;
            color=lightgrey;
            node [shape = box];
            "bb0" -> "bb1";
            "bb0" -> "bb3";
            "bb1" -> "bb4";
            "bb3" -> "bb2";
            "bb4" -> "bb2";
        }
        ```
        <|im_end|>
        <|im_start|>user
        ```
        digraph G {
            label="bb2";
            labelloc=t;
            labeljust=c;
            style=filled;
            color=lightgrey;
            node [shape = box];
            "bb0" -> "bb1";
            "bb0" -> "bb3";
            "bb1" -> "bb4";
            "bb3" -> "bb2";
            "bb4" -> "bb2";
        }
        ```
        <|im_end|>
        <|im_start|>system
        Great!
        <|im_end|>
        <|im_start|>user

        <|im_end|>
        <|im_start|>system
        Thank you for your time. Your input will help make the world a better place.
        <|im_end|>
        <|im_start|>user
        Bye
        <|im_end|>
        <|im_start|>system
        Bye!
        <|im_end|>
        <|endoftext|>
        """

    def validate(self, examples):
        """
        Check a few of the examples to make sure the task is solvable.

        If you set a validation_docs, these will be checked for you.
        """
        for example in examples:
            assert (
                "<|endoftext|>" in example["dialogue"]
            ), "Dataset is missing end-of-text token."
            assert (
                "<|im_start|>" in example["dialogue"]
            ), "Dataset is missing input delimiter token."
            assert (
                "<|im_end|>" in example["dialogue"]
            ), "Dataset is missing output delimiter token."
            assert (
                example["dialogue"].count("<|im_start|>") == 2
            ), "Dataset is missing input delimiter token."
            assert (
                example["dialogue"].count("<|im_end|>") == 2
            ), "Dataset is missing output delimiter token."
            assert (
                example["dialogue"].count("<|endoftext|>") == 1
            ), "Dataset is missing end-of-text token."
            assert (
                example["dialogue"].index("<|im_end|>") > example["dialogue"].index("<|im_start|>")
            ), \
                "Dataset has an improperly formatted training example with two input delimiters."
            assert (
                example["dialogue"].index("<|endoftext|>") > example["dialogue"].index("<|im_end|>")
            ), \
                "Dataset has an improperly formatted training example with two output delimiters."

    def doc_to_text(self, doc):
        return doc["dialogue"]

    def doc_to_target(self, doc):
        return "None"

    def construct_requests(self, doc, ctx):
        """ Uses RequestFactory to construct Requests and returns an iterable of
        Requests which will be sent to the LM.

        :param doc:
            The document as returned from training_docs, validation_docs, or test_docs.
        :param ctx: str
            The context string, generated by fewshot_context. This includes the natural
            language description, as well as the few shot examples, and the question
            part of the document for `doc`.
        """
        # ignore the context, it's in the doc
        return RequestFactory.get(
            "openai-gpt3-user-to-bot-format"
        )(
            doc["dialogue"],
            description="Input: A person asks a question in a programming language about a programming task. For example, they may ask about how to sum all the elements in a list or how to sort a list of dictionaries by values. Answer: A textual description of how to complete the task. For example, you might describe which functions to use and which arguments those functions take.",
        )

    def process_results(self, doc, results):
        """Take a single document and the LM results and evaluates, returning a
        dict where keys are the names of submetrics and values are the values of
        the metric for that one document

        :param doc:
            The document as returned from training_docs, validation_docs, or test_docs.
        :param results:
            The results of the requests created in construct_requests.
        """
        pred = results[0].strip()
        gold = (
            doc["dialogue"]
            .split("<|im_end|>")[1]
            .split("<|endoftext|>")[0]
            .strip()
        )
        return {"em": int(gold == pred)}

    def aggregation(self):
        """
        :returns: {str: [metric_score] -> float}
            A dictionary where keys are the names of submetrics and values are
            functions that aggregate a list of metric scores
        """
        # TODO: use more standard/less ad-hoc way to compute EM
        return {"em": mean}

    def higher_is_better(self):
        """
        :returns: {str: bool}
            A dictionary where keys are the names of submetrics and values are
            whether a higher value of the submetric is better
        """
        return {"em": True}